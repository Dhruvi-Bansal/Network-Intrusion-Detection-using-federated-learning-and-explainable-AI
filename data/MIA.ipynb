{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "bzkXlAkL5ShS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "KUkcdjup5VvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ee2db861-827d-4749-c1a6-ed82eb076d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7570174-bdf4-4316-b9f1-1c404bab65e1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b7570174-bdf4-4316-b9f1-1c404bab65e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIkXc03xlyNs",
        "outputId": "6093aa22-e8e5-44e7-a1ad-d0dea1283795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dhoogla/unswnb15 -q\n",
        "!unzip -q unswnb15.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzvKHqjPly-7",
        "outputId": "eacd8a63-00cd-4f2e-d3a6-2df7ba1fe6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/dhoogla/unswnb15\n",
            "License(s): CC-BY-NC-SA-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aryashah2k/nfuqnidsv2-network-intrusion-detection-dataset -q\n",
        "!unzip -q nfuqnidsv2-network-intrusion-detection-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2NDgOsQl14k",
        "outputId": "9daf8356-7917-4135-b93e-dc4deded2d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aryashah2k/nfuqnidsv2-network-intrusion-detection-dataset\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "unsw = pd.read_parquet('UNSW_NB15_training-set.parquet')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "unsw.drop(columns=[c for c in ['srcip', 'dstip', 'sport', 'dsport', 'stime', 'ltime'] if c in unsw.columns],\n",
        "           inplace=True)\n",
        "\n",
        "# Label encode categorical features\n",
        "for col in ['proto', 'service', 'state']:\n",
        "    if col in unsw.columns:\n",
        "        le = LabelEncoder()\n",
        "        unsw[col] = le.fit_transform(unsw[col].astype(str))\n",
        "\n",
        "# Handle missing labels and encode attack labels\n",
        "unsw['attack_cat'] = unsw['attack_cat'].fillna('Normal')\n",
        "le_attack = LabelEncoder()\n",
        "unsw['label_encoded'] = le_attack.fit_transform(unsw['attack_cat'])\n",
        "\n",
        "# Drop original label column\n",
        "if 'attack_cat' in unsw.columns:\n",
        "    unsw.drop(columns=['attack_cat'], inplace=True)\n",
        "\n",
        "# Replace inf/nan\n",
        "unsw = unsw.replace([float('inf'), -float('inf')], np.nan).dropna()\n",
        "\n",
        "# Scale numeric features\n",
        "numeric_cols_unsw = unsw.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "numeric_cols_unsw = [c for c in numeric_cols_unsw if c != 'label_encoded']\n",
        "scaler = MinMaxScaler()\n",
        "unsw[numeric_cols_unsw] = scaler.fit_transform(unsw[numeric_cols_unsw])\n",
        "\n",
        "# Save client 1\n",
        "unsw.to_csv(\"/content/client1_UNSW.csv\", index=False)\n",
        "print(\"UNSW dataset saved as client1_UNSW.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHSayxOXl4P7",
        "outputId": "1a09728b-def8-4682-aea8-96a892713868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSW dataset saved as client1_UNSW.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nfq = pd.read_csv(\"NF-UQ-NIDS-v2.csv\", nrows=200000)\n",
        "nfq = nfq.sample(n=175341, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "nfq.drop(columns=[c for c in ['Flow ID', 'Source IP', 'Destination IP',\n",
        "                              'Src Port', 'Dst Port', 'Timestamp',\n",
        "                              'StartTime', 'EndTime'] if c in nfq.columns],\n",
        "         inplace=True)\n",
        "\n",
        "# Label encode categorical features\n",
        "for col in ['proto', 'service', 'state']:\n",
        "    if col in nfq.columns:\n",
        "        le = LabelEncoder()\n",
        "        nfq[col] = le.fit_transform(nfq[col].astype(str))\n",
        "\n",
        "# Encode attack labels\n",
        "nfq['Attack'] = nfq['Attack'].replace('Benign', 'Normal').fillna('Normal')\n",
        "base_mapping = dict(zip(le_attack.classes_, le_attack.transform(le_attack.classes_)))\n",
        "current_max = max(base_mapping.values())\n",
        "for att in nfq['Attack'].unique():\n",
        "    if att not in base_mapping:\n",
        "        current_max += 1\n",
        "        base_mapping[att] = current_max\n",
        "nfq['label_encoded'] = nfq['Attack'].map(base_mapping).astype(int)\n",
        "\n",
        "# Drop original attack column\n",
        "if 'Attack' in nfq.columns:\n",
        "    nfq.drop(columns=['Attack'], inplace=True)\n",
        "\n",
        "if 'FLOW_DURATION_MILLISECONDS' in nfq.columns:\n",
        "    nfq['FLOW_DURATION_MILLISECONDS'] = nfq['FLOW_DURATION_MILLISECONDS'] / 1000\n",
        "\n",
        "mapping = {\n",
        "    'FLOW_DURATION_MILLISECONDS': 'dur',\n",
        "    'PROTOCOL': 'proto',\n",
        "    'IN_PKTS': 'spkts',\n",
        "    'OUT_PKTS': 'dpkts',\n",
        "    'IN_BYTES': 'sbytes',\n",
        "    'OUT_BYTES': 'dbytes',\n",
        "    'SRC_TO_DST_AVG_THROUGHPUT': 'sload',\n",
        "    'DST_TO_SRC_AVG_THROUGHPUT': 'dload',\n",
        "    'RETRANSMITTED_IN_BYTES': 'sloss',\n",
        "    'RETRANSMITTED_OUT_BYTES': 'dloss',\n",
        "    'LONGEST_FLOW_PKT': 'sinpkt',\n",
        "    'SHORTEST_FLOW_PKT': 'dinpkt',\n",
        "    'TCP_WIN_MAX_OUT': 'dwin',\n",
        "    'TCP_WIN_MAX_IN': 'swin',\n",
        "    'IPV4_SRC_ADDR': 'srcip',\n",
        "    'L4_SRC_PORT': 'srcport',\n",
        "    'IPV4_DST_ADDR':'dstip',\n",
        "    'L4_DST_PORT': 'dstport',\n",
        "    'L7_PROTO': 'service',\n",
        "    'TCP_FLAGS': 'state',\n",
        "}\n",
        "\n",
        "nfq.rename(columns=mapping, inplace=True)\n",
        "\n",
        "# Keep only columns that exist in UNSW + label_encoded\n",
        "common_features = [c for c in unsw.columns if c != 'label_encoded' and c in nfq.columns]\n",
        "\n",
        "# Drop columns in NFQ that are not mapped\n",
        "nfq = nfq[common_features + ['label_encoded']]\n",
        "\n",
        "# Scale numeric features\n",
        "numeric_cols_nfq = nfq.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "numeric_cols_nfq = [c for c in numeric_cols_nfq if c != 'label_encoded']\n",
        "nfq[numeric_cols_nfq] = scaler.fit_transform(nfq[numeric_cols_nfq])\n",
        "\n",
        "# Save client 2\n",
        "nfq.to_csv(\"/content/client2_NFQ.csv\", index=False)\n",
        "print(\"NF-UQ dataset saved as client2_NFQ.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C6aNDIfl40C",
        "outputId": "36881af6-5e99-411a-d003-5b5f99a002ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NF-UQ dataset saved as client2_NFQ.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define broader unified attack categories\n",
        "attack_mapping_unified = {\n",
        "    # Normal traffic\n",
        "    'Normal': 'Normal',\n",
        "    'Benign': 'Normal',\n",
        "\n",
        "    # Denial of Service\n",
        "    'DoS': 'DoS',\n",
        "    'DDoS': 'DoS',\n",
        "    'DoS GoldenEye': 'DoS',\n",
        "    'DoS Hulk': 'DoS',\n",
        "    'DoS Slowhttptest': 'DoS',\n",
        "    'DoS Slowloris': 'DoS',\n",
        "    'Service DoS': 'DoS',\n",
        "\n",
        "    # Scanning & Reconnaissance\n",
        "    'Reconnaissance': 'Reconnaissance',\n",
        "    'PortScan': 'Reconnaissance',\n",
        "    'Scanning': 'Reconnaissance',\n",
        "    'Fuzzers': 'Reconnaissance',\n",
        "\n",
        "    # Exploits / Injection\n",
        "    'Exploits': 'Exploits',\n",
        "    'Shellcode': 'Exploits',\n",
        "    'Worms': 'Exploits',\n",
        "    'Backdoor': 'Exploits',\n",
        "    'Generic': 'Exploits',\n",
        "    'SQL Injection': 'Exploits',\n",
        "    'Command Injection': 'Exploits',\n",
        "    'Code Injection': 'Exploits',\n",
        "\n",
        "    # Information Theft\n",
        "    'Theft': 'Theft',\n",
        "    'Data Exfiltration': 'Theft',\n",
        "    'Data Theft': 'Theft',\n",
        "    'Information Gathering': 'Theft',\n",
        "\n",
        "    # Web-based Attacks\n",
        "    'Web Attack': 'Web Attack',\n",
        "    'Brute Force': 'Web Attack',\n",
        "    'Cross Site Scripting': 'Web Attack',\n",
        "    'XSS': 'Web Attack',\n",
        "    'Infiltration': 'Web Attack',\n",
        "\n",
        "    # Generic Malware\n",
        "    'Trojan': 'Malware',\n",
        "    'Virus': 'Malware',\n",
        "    'Botnet': 'Malware',\n",
        "    'Malware': 'Malware',\n",
        "}\n",
        "\n",
        "if 'label_encoded' in unsw.columns:\n",
        "    # Need to recover original label names temporarily\n",
        "    unsw_labels = le_attack.inverse_transform(unsw['label_encoded'])\n",
        "    unsw['UnifiedAttack'] = [attack_mapping_unified.get(a, 'Other') for a in unsw_labels]\n",
        "\n",
        "if 'label_encoded' in nfq.columns:\n",
        "    # If NFQ was mapped via base_mapping, get inverse\n",
        "    inv_base_mapping = {v: k for k, v in base_mapping.items()}\n",
        "    nfq_labels = [inv_base_mapping.get(a, 'Normal') for a in nfq['label_encoded']]\n",
        "    nfq['UnifiedAttack'] = [attack_mapping_unified.get(a, 'Other') for a in nfq_labels]\n",
        "\n",
        "all_labels = list(set(unsw['UnifiedAttack'].unique()).union(set(nfq['UnifiedAttack'].unique())))\n",
        "le_unified = LabelEncoder()\n",
        "le_unified.fit(all_labels)\n",
        "\n",
        "unsw['label_encoded'] = le_unified.transform(unsw['UnifiedAttack'])\n",
        "nfq['label_encoded'] = le_unified.transform(nfq['UnifiedAttack'])\n",
        "\n",
        "# Update base mapping with unified labels\n",
        "base_mapping = dict(zip(le_unified.classes_, le_unified.transform(le_unified.classes_)))\n",
        "\n",
        "print(\"Unified Attack Mapping:\")\n",
        "for k, v in base_mapping.items():\n",
        "    print(f\"{v}: {k}\")\n",
        "\n",
        "# Drop helper columns\n",
        "unsw.drop(columns=['UnifiedAttack'], inplace=True)\n",
        "nfq.drop(columns=['UnifiedAttack'], inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IloF_9w3l6k1",
        "outputId": "a8383091-1630-43b9-e49a-395610ac9bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unified Attack Mapping:\n",
            "0: DoS\n",
            "1: Exploits\n",
            "2: Normal\n",
            "3: Other\n",
            "4: Reconnaissance\n",
            "5: Theft\n",
            "6: Web Attack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count samples per attack type in both datasets\n",
        "unsw_counts = unsw['label_encoded'].value_counts().rename_axis('label_encoded').reset_index(name='UNSW_count')\n",
        "nfq_counts = nfq['label_encoded'].value_counts().rename_axis('label_encoded').reset_index(name='NFQ_count')\n",
        "\n",
        "# Merge counts by label\n",
        "attack_counts = pd.merge(unsw_counts, nfq_counts, on='label_encoded', how='outer').fillna(0)\n",
        "\n",
        "# Map label codes to class names using base_mapping\n",
        "inv_base_mapping = {v: k for k, v in base_mapping.items()}\n",
        "attack_counts['Attack_Type'] = attack_counts['label_encoded'].map(inv_base_mapping)\n",
        "\n",
        "# Add combined total count\n",
        "attack_counts['Total_Samples'] = attack_counts['UNSW_count'] + attack_counts['NFQ_count']\n",
        "\n",
        "# Reorder columns for readability\n",
        "attack_counts = attack_counts[['Attack_Type', 'label_encoded', 'UNSW_count', 'NFQ_count', 'Total_Samples']]\n",
        "\n",
        "# Sort by total samples (descending)\n",
        "attack_counts = attack_counts.sort_values(by='Total_Samples', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n===== Attack Label Distribution Across Datasets =====\")\n",
        "print(attack_counts.to_string(index=False))\n",
        "print(\"=====================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEnFVWRdl8My",
        "outputId": "bc26e1d6-096c-49ab-9cfe-8b471c6a1565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Attack Label Distribution Across Datasets =====\n",
            "   Attack_Type  label_encoded  UNSW_count  NFQ_count  Total_Samples\n",
            "        Normal              2     56000.0      57609       113609.0\n",
            "           DoS              0     12264.0      91913       104177.0\n",
            "      Exploits              1     76402.0        143        76545.0\n",
            "Reconnaissance              4     28675.0       6103        34778.0\n",
            "         Other              3      2000.0      19272        21272.0\n",
            "    Web Attack              6         0.0        298          298.0\n",
            "         Theft              5         0.0          3            3.0\n",
            "=====================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Remove 'Theft' samples if present\n",
        "if 'Theft' in base_mapping:\n",
        "    theft_label = base_mapping['Theft']\n",
        "\n",
        "    # Filter out Theft samples\n",
        "    unsw = unsw[unsw['label_encoded'] != theft_label].reset_index(drop=True)\n",
        "    nfq = nfq[nfq['label_encoded'] != theft_label].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Removed 'Theft' attacks (label code = {theft_label}) from both datasets.\")\n",
        "else:\n",
        "    print(\"No 'Theft' label found — skipping removal.\")\n",
        "\n",
        "# 2 Reindex remaining labels\n",
        "# Extract all unique labels from both datasets\n",
        "unique_labels = sorted(list(set(unsw['label_encoded'].unique()) | set(nfq['label_encoded'].unique())))\n",
        "\n",
        "# Create a new sequential mapping (0,1,2,...)\n",
        "new_label_mapping = {old: new for new, old in enumerate(unique_labels)}\n",
        "\n",
        "# Apply new mapping\n",
        "unsw['label_encoded'] = unsw['label_encoded'].map(new_label_mapping)\n",
        "nfq['label_encoded'] = nfq['label_encoded'].map(new_label_mapping)\n",
        "\n",
        "# 3 Update base_mapping to reflect new indices\n",
        "inv_base_mapping = {v: k for k, v in base_mapping.items()}\n",
        "base_mapping = {inv_base_mapping[old]: new for old, new in new_label_mapping.items() if old in inv_base_mapping}\n",
        "\n",
        "# 4 Print updated label summary\n",
        "print(\"\\n Final Unified Attack Mapping (after removing Theft & reindexing):\")\n",
        "for k, v in base_mapping.items():\n",
        "    print(f\"{v}: {k}\")\n",
        "\n",
        "# 5 Optional: Display new label counts\n",
        "print(\"\\nUpdated label distribution:\")\n",
        "unsw_counts = unsw['label_encoded'].value_counts().sort_index()\n",
        "nfq_counts = nfq['label_encoded'].value_counts().sort_index()\n",
        "for lbl in sorted(base_mapping.values()):\n",
        "    attack_name = [k for k, v in base_mapping.items() if v == lbl][0]\n",
        "    print(f\"{attack_name:<15} | UNSW: {unsw_counts.get(lbl,0):<6} | NFQ: {nfq_counts.get(lbl,0):<6}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLbS5HW4qC5k",
        "outputId": "1b05bd75-76f2-4fcc-dc00-357b51e4b1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 'Theft' attacks (label code = 5) from both datasets.\n",
            "\n",
            "✅ Final Unified Attack Mapping (after removing Theft & reindexing):\n",
            "0: DoS\n",
            "1: Exploits\n",
            "2: Normal\n",
            "3: Other\n",
            "4: Reconnaissance\n",
            "5: Web Attack\n",
            "\n",
            "Updated label distribution:\n",
            "DoS             | UNSW: 12264  | NFQ: 91913 \n",
            "Exploits        | UNSW: 76402  | NFQ: 143   \n",
            "Normal          | UNSW: 56000  | NFQ: 57609 \n",
            "Other           | UNSW: 2000   | NFQ: 19272 \n",
            "Reconnaissance  | UNSW: 28675  | NFQ: 6103  \n",
            "Web Attack      | UNSW: 0      | NFQ: 298   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIA FOR DECISION TREE (TRADITIONAL ML MODEL)"
      ],
      "metadata": {
        "id": "AR1sFz-BmDCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "combined_df = pd.concat([unsw, nfq], axis=0).reset_index(drop=True)\n",
        "X = combined_df.drop(columns=['label_encoded'])\n",
        "y = combined_df['label_encoded']\n",
        "\n",
        "print(\"Feature count:\", X.shape[1])\n",
        "print(\"Unique classes:\", y.nunique())\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfkNFQJ_mBan",
        "outputId": "49ec6a8d-b01b-4af5-d964-fcf52e8abfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count: 35\n",
            "Unique classes: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_model = files.upload()\n",
        "\n",
        "os.makedirs(\"uploaded_models\", exist_ok=True)\n",
        "for fname, bytestr in uploaded_model.items():\n",
        "    path = os.path.join(\"uploaded_models\", fname)\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(bytestr)\n",
        "    print(f\"Saved: {path}\")\n",
        "model = None\n",
        "preferred = os.path.join(\"uploaded_models\", \"decision_tree_model.pkl\")\n",
        "if os.path.exists(preferred):\n",
        "    model = joblib.load(preferred)\n",
        "    print(f\"Loaded model from {preferred}\")\n",
        "else:\n",
        "    for f in os.listdir(\"uploaded_models\"):\n",
        "        if f.lower().endswith((\".pkl\", \".joblib\")):\n",
        "            model = joblib.load(os.path.join(\"uploaded_models\", f))\n",
        "            print(f\"Loaded model from uploaded_models/{f}\")\n",
        "            break\n",
        "\n",
        "if model is None:\n",
        "    raise FileNotFoundError(\"No .pkl/.joblib model file found in uploaded files.\")\n",
        "\n",
        "print(\"Model type:\", type(model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "m3h7204nmJ8a",
        "outputId": "b7548883-a252-4474-e69b-4e6ac0b1e2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e37a65e-dbea-4764-a3c2-17a7051f9f8e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e37a65e-dbea-4764-a3c2-17a7051f9f8e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving decision_tree_model.pkl to decision_tree_model (1).pkl\n",
            "Saved: uploaded_models/decision_tree_model (1).pkl\n",
            "Loaded model from uploaded_models/decision_tree_model.pkl\n",
            "Model type: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_mem_val, X_mem_eval, y_mem_val, y_mem_eval = train_test_split(\n",
        "    X_train, y_train, test_size=0.5, random_state=42, stratify=y_train\n",
        ")\n",
        "X_nonmem_val, X_nonmem_eval, y_nonmem_val, y_nonmem_eval = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")"
      ],
      "metadata": {
        "id": "8QAV0zRGoK7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def true_class_confidence(model_obj, X, y_true):\n",
        "    if hasattr(model_obj, \"predict_proba\"):\n",
        "        proba = model_obj.predict_proba(X)\n",
        "        y_true = np.clip(y_true, 0, proba.shape[1]-1)\n",
        "        return proba[np.arange(len(y_true)), y_true]\n",
        "    else:\n",
        "        preds = model_obj.predict(X)\n",
        "        return (preds == y_true).astype(float)"
      ],
      "metadata": {
        "id": "RuWuPoDNmv_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_mem_val = true_class_confidence(model, X_mem_val, y_mem_val)\n",
        "scores_nonmem_val = true_class_confidence(model, X_nonmem_val, y_nonmem_val)\n",
        "\n",
        "all_scores = np.concatenate([scores_mem_val, scores_nonmem_val])\n",
        "labels = np.concatenate([np.ones_like(scores_mem_val), np.zeros_like(scores_nonmem_val)])\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(labels, all_scores)\n",
        "balanced_acc = (tpr + (1 - fpr)) / 2\n",
        "best_threshold = thresholds[np.argmax(balanced_acc)]\n",
        "\n",
        "print(f\" Optimal threshold found: {best_threshold:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg2e0omPnFDD",
        "outputId": "4a6b6301-bead-4536-cbc9-e5905057c607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Optimal threshold found: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_mem_eval = true_class_confidence(model, X_mem_eval, y_mem_eval)\n",
        "scores_nonmem_eval = true_class_confidence(model, X_nonmem_eval, y_nonmem_eval)\n",
        "\n",
        "pred_mem_eval = (scores_mem_eval >= best_threshold).astype(int)\n",
        "pred_nonmem_eval = (scores_nonmem_eval >= best_threshold).astype(int)\n",
        "\n",
        "true_mem_eval = np.ones_like(pred_mem_eval)\n",
        "true_nonmem_eval = np.zeros_like(pred_nonmem_eval)\n",
        "\n",
        "pred_all = np.concatenate([pred_mem_eval, pred_nonmem_eval])\n",
        "true_all = np.concatenate([true_mem_eval, true_nonmem_eval])\n",
        "\n",
        "ASR = accuracy_score(true_all, pred_all)\n",
        "privacy_score = 1 - ASR\n",
        "attack_auc = roc_auc_score(true_all, np.concatenate([scores_mem_eval, scores_nonmem_eval]))\n",
        "\n",
        "print(\"\\n--- Membership Inference Attack Results ---\")\n",
        "print(f\"Attack Success Rate (ASR): {ASR:.4f}\")\n",
        "print(f\"Privacy Score (1 - ASR): {privacy_score:.4f}\")\n",
        "print(f\"Attack AUC: {attack_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXmyL0vKnHN6",
        "outputId": "58fe1541-0e92-4137-861a-60fabe01776e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Membership Inference Attack Results ---\n",
            "Attack Success Rate (ASR): 0.7191\n",
            "Privacy Score (1 - ASR): 0.2809\n",
            "Attack AUC: 0.5013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"mia_results\", exist_ok=True)\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    \"ASR\": float(ASR),\n",
        "    \"privacy_score\": float(privacy_score),\n",
        "    \"attack_auc\": float(attack_auc),\n",
        "    \"threshold\": float(best_threshold),\n",
        "}\n",
        "with open(\"mia_results/mia_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, lw=2, label=f\"AUC={attack_auc:.3f}\")\n",
        "plt.plot([0,1],[0,1],'--',color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"MIA ROC Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"mia_results/mia_roc_curve.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Histogram of member vs non-member scores\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.hist(scores_mem_eval, bins=40, alpha=0.6, label=\"Members\")\n",
        "plt.hist(scores_nonmem_eval, bins=40, alpha=0.6, label=\"Non-Members\")\n",
        "plt.axvline(best_threshold, color='k', linestyle='--', label='Threshold')\n",
        "plt.legend()\n",
        "plt.title(\"Confidence Distribution: Members vs Non-Members\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"mia_results/mia_score_histogram.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Confusion matrix for attack predictions\n",
        "cm = confusion_matrix(true_all, pred_all)\n",
        "ConfusionMatrixDisplay(cm, display_labels=[\"Non-Member\",\"Member\"]).plot(cmap=\"Blues\")\n",
        "plt.title(\"Attack Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"mia_results/mia_confusion_matrix.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Save everything as zip for download\n",
        "import shutil\n",
        "shutil.make_archive(\"mia_results\", \"zip\", \"mia_results\")\n",
        "files.download(\"mia_results.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mRkjbH1hnKR_",
        "outputId": "d5fe5e5a-4b62-4a5c-8709-116261a9fbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ec79cb39-0aec-4fe0-94ef-ea42dd24ebff\", \"mia_results.zip\", 246534)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIA FOR FEDAVG MODEL\n"
      ],
      "metadata": {
        "id": "6G3cMUFQqrP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-encode labels\n",
        "le = LabelEncoder()\n",
        "all_labels = pd.concat([unsw['label_encoded'], nfq['label_encoded']])\n",
        "le.fit(all_labels)\n",
        "unsw['label_encoded'] = le.transform(unsw['label_encoded'])\n",
        "nfq['label_encoded'] = le.transform(nfq['label_encoded'])"
      ],
      "metadata": {
        "id": "XQWRCJmhquqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features per client\n",
        "common_features = [c for c in unsw.columns if c != 'label_encoded' and c in nfq.columns]\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "X1 = pd.DataFrame(scaler1.fit_transform(unsw[common_features]), columns=common_features)\n",
        "X2 = pd.DataFrame(scaler2.fit_transform(nfq[common_features]), columns=common_features)\n",
        "y1 = unsw['label_encoded'].copy()\n",
        "y2 = nfq['label_encoded'].copy()"
      ],
      "metadata": {
        "id": "DckvkZh5q1_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "uO0nA57hq36z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2. Stratified Train/Test Split\n",
        "# -----------------------------\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
        "X1_np, y1_np = X1.values.astype('float32'), y1.values.astype('int32')\n",
        "X2_np, y2_np = X2.values.astype('float32'), y2.values.astype('int32')\n",
        "\n",
        "train_idx1, test_idx1 = next(sss.split(X1_np, y1_np))\n",
        "train_idx2, test_idx2 = next(sss.split(X2_np, y2_np))\n",
        "\n",
        "X1_train, X1_test = X1_np[train_idx1], X1_np[test_idx1]\n",
        "y1_train, y1_test = y1_np[train_idx1], y1_np[test_idx1]\n",
        "X2_train, X2_test = X2_np[train_idx2], X2_np[test_idx2]\n",
        "y2_train, y2_test = y2_np[train_idx2], y2_np[test_idx2]\n",
        "\n",
        "num_classes = len(le.classes_)"
      ],
      "metadata": {
        "id": "YZE7QwmtrE84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "-6xKHKNgrHgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded_fedavg = files.upload()\n",
        "for fn in uploaded_fedavg.keys():\n",
        "  if fn.endswith(\".h5\"):\n",
        "    model_path = fn\n",
        "\n",
        "model = load_model(model_path)\n",
        "print(f\"Loaded model from: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "zJk6sMfiskAo",
        "outputId": "c37b3851-cb0f-47f7-ccc2-3d1cc00cb9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ee871ae4-065d-455c-8d70-1a95af3c5119\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ee871ae4-065d-455c-8d70-1a95af3c5119\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving global_model_full.h5 to global_model_full (2).h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from: global_model_full (2).h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def privacy_predict_probs(model, X,\n",
        "                          top_k=None,\n",
        "                          round_ndigits=None,\n",
        "                          rng_seed=None):\n",
        "\n",
        "    if rng_seed is not None:\n",
        "        np.random.seed(rng_seed)\n",
        "\n",
        "    preds = model.predict(X, verbose=0)\n",
        "    preds = np.asarray(preds)\n",
        "\n",
        "    if preds.ndim == 1:\n",
        "        probs_pos = preds.ravel()\n",
        "        probs = np.vstack([1 - probs_pos, probs_pos]).T\n",
        "    elif preds.shape[1] == 1:\n",
        "        probs_pos = preds.ravel()\n",
        "        probs = np.vstack([1 - probs_pos, probs_pos]).T\n",
        "    else:\n",
        "        probs = preds\n",
        "        if np.any(probs < 0) or np.max(probs) > 1.0001 or np.min(probs) < -0.0001:\n",
        "            exp = np.exp(probs - np.max(probs, axis=1, keepdims=True))\n",
        "            probs = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "\n",
        "    if top_k is not None:\n",
        "        k = int(top_k)\n",
        "        if k < probs.shape[1]:\n",
        "            idx = np.argsort(probs, axis=1)[:, ::-1]  # descending indices\n",
        "            mask = np.zeros_like(probs, dtype=bool)\n",
        "            rows = np.arange(probs.shape[0])[:, None]\n",
        "            topk_idx = idx[:, :k]\n",
        "            mask[rows, topk_idx] = True\n",
        "            probs = probs * mask.astype(float)\n",
        "\n",
        "    if round_ndigits is not None:\n",
        "        nd = int(round_ndigits)\n",
        "        probs = np.round(probs, decimals=nd)\n",
        "\n",
        "    row_sums = probs.sum(axis=1, keepdims=True)\n",
        "    zero_rows = (row_sums.squeeze() == 0)\n",
        "    if np.any(zero_rows):\n",
        "        probs[zero_rows, :] = 1.0 / probs.shape[1]\n",
        "        row_sums = probs.sum(axis=1, keepdims=True)\n",
        "    probs = probs / row_sums\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "l-c81lQltfB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "OUT_ROOT = \"/content/mia_results_fedavg\"\n",
        "ZIP_PATH = os.path.join(OUT_ROOT, \"mia_results_clients.zip\")"
      ],
      "metadata": {
        "id": "pWTHvVJ1v1e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_client(model, X_train, X_test, y_train, y_test, client_name=\"client\"):\n",
        "    import os, json\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import (\n",
        "        roc_curve, accuracy_score, roc_auc_score,\n",
        "        confusion_matrix, classification_report\n",
        "    )\n",
        "\n",
        "    # ---- Create output directory safely ----\n",
        "    outdir = os.path.join(\"/content/mia_results_fedavg\", f\"mia_results_{client_name}\")\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    # ---- Get model confidence scores ----\n",
        "    def get_probs(m, X):\n",
        "        preds = m.predict(X, verbose=0)\n",
        "        preds = np.asarray(preds)\n",
        "        if preds.ndim == 1:\n",
        "            probs_pos = preds.ravel()\n",
        "            probs = np.vstack([1 - probs_pos, probs_pos]).T\n",
        "        elif preds.shape[1] == 1:\n",
        "            probs_pos = preds.ravel()\n",
        "            probs = np.vstack([1 - probs_pos, probs_pos]).T\n",
        "        else:\n",
        "            probs = preds\n",
        "            if np.any(probs < 0) or np.max(probs) > 1.0001 or np.min(probs) < -0.0001:\n",
        "                exp = np.exp(probs - np.max(probs, axis=1, keepdims=True))\n",
        "                probs = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "        return probs\n",
        "\n",
        "    probs_train = get_probs(model, X_train)\n",
        "    probs_test  = get_probs(model, X_test)\n",
        "    conf_train = np.max(probs_train, axis=1)\n",
        "    conf_test  = np.max(probs_test, axis=1)\n",
        "\n",
        "    y_member_train = np.ones(len(conf_train), dtype=int)\n",
        "    y_member_test  = np.zeros(len(conf_test), dtype=int)\n",
        "    conf_all = np.concatenate([conf_train, conf_test])\n",
        "    y_member_all = np.concatenate([y_member_train, y_member_test])\n",
        "\n",
        "    # ---- ROC & best threshold ----\n",
        "    fpr, tpr, thresholds = roc_curve(y_member_all, conf_all)\n",
        "    youden = tpr - fpr\n",
        "    best_idx = np.argmax(youden)\n",
        "    best_thresh = thresholds[best_idx]\n",
        "\n",
        "    attack_preds = (conf_all >= best_thresh).astype(int)\n",
        "    ASR = accuracy_score(y_member_all, attack_preds)\n",
        "    AUC = roc_auc_score(y_member_all, conf_all)\n",
        "    cm = confusion_matrix(y_member_all, attack_preds, labels=[0,1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    member_acc = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    nonmember_acc = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    privacy_score = 1.0 - ASR\n",
        "\n",
        "    # ---- Save classification report ----\n",
        "    clr_text = classification_report(y_member_all, attack_preds, zero_division=0)\n",
        "    clr = classification_report(y_member_all, attack_preds, output_dict=True, zero_division=0)\n",
        "    with open(os.path.join(outdir, \"classification_report.txt\"), \"w\") as f:\n",
        "        f.write(clr_text)\n",
        "    pd.DataFrame(clr).transpose().to_csv(os.path.join(outdir, \"classification_report.csv\"))\n",
        "\n",
        "    # ---- Save summary JSON ----\n",
        "    summary = {\n",
        "        \"client\": client_name,\n",
        "        \"best_threshold\": float(best_thresh),\n",
        "        \"AUC\": float(AUC),\n",
        "        \"ASR\": float(ASR),\n",
        "        \"privacy_score\": float(privacy_score),\n",
        "        \"TP\": int(tp), \"FP\": int(fp), \"FN\": int(fn), \"TN\": int(tn),\n",
        "        \"member_TPR\": float(member_acc),\n",
        "        \"nonmember_TNR\": float(nonmember_acc)\n",
        "    }\n",
        "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    # ---- Save ROC plot ----\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC={AUC:.4f}\")\n",
        "    plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC Curve - {client_name}\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(outdir, \"roc_curve.png\"))\n",
        "    plt.close()\n",
        "    print(summary)\n",
        "\n",
        "    print(f\" Results saved for {client_name} → {outdir}\")\n",
        "    return outdir, summary\n"
      ],
      "metadata": {
        "id": "oPtKPhaGtf8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clients_dirs = []\n",
        "out1, sum1 = analyze_client(model, X1_train, X1_test, y1_train, y1_test, client_name=\"client1\")\n",
        "out2, sum2 = analyze_client(model, X2_train, X2_test, y2_train, y2_test, client_name=\"client2\")\n",
        "\n",
        "import zipfile, os\n",
        "zip_path = \"/content/mia_results_fedavg/mia_results_clients.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for d in [out1, out2]:\n",
        "        for root, _, files in os.walk(d):\n",
        "            for f in files:\n",
        "                full = os.path.join(root, f)\n",
        "                arc = os.path.relpath(full, \"/content/mia_results_fedavg\")\n",
        "                zf.write(full, arc)\n",
        "print(\" All results zipped at:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fClNbTx2tiN1",
        "outputId": "e5e95489-ed3a-4394-e34e-e77e28a64981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'client': 'client1', 'best_threshold': 0.8181066513061523, 'AUC': 0.5016818320198441, 'ASR': 0.5660969197164383, 'privacy_score': 0.4339030802835617, 'TP': 85371, 'FP': 21180, 'FN': 54901, 'TN': 13889, 'member_TPR': 0.6086104140526977, 'nonmember_TNR': 0.3960477914967635}\n",
            " Results saved for client1 → /content/mia_results_fedavg/mia_results_client1\n",
            "{'client': 'client2', 'best_threshold': 0.7643875479698181, 'AUC': 0.4989476834216375, 'ASR': 0.6338044234564099, 'privacy_score': 0.36619557654359014, 'TP': 101352, 'FP': 25290, 'FN': 38918, 'TN': 9778, 'member_TPR': 0.7225493690739289, 'nonmember_TNR': 0.2788297022926885}\n",
            " Results saved for client2 → /content/mia_results_fedavg/mia_results_client2\n",
            " All results zipped at: /content/mia_results_fedavg/mia_results_clients.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/mia_results_fedavg/mia_results_clients.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3sEC4822xPcO",
        "outputId": "27493695-39dc-4a04-bfa9-e34db0ea2989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ccd4623e-03dd-4bed-9229-f20d70a13725\", \"mia_privacy_results.zip\", 164315)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIA FOR FEDPROX"
      ],
      "metadata": {
        "id": "ob4lUumix96I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded_fedprox = files.upload()\n",
        "\n",
        "for fn in uploaded_fedprox.keys():\n",
        "    if fn.endswith(\".h5\"):\n",
        "        model_path = fn\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(model_path)\n",
        "print(f\"Loaded model from: {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "4xMITUFtyAOW",
        "outputId": "55d6f030-a3bc-4901-ae54-fbbf0354b7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-033ea804-4d3e-4ca5-9ea3-123798a2a559\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-033ea804-4d3e-4ca5-9ea3-123798a2a559\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving global_model_full.h5 to global_model_full (1).h5\n",
            "Loaded model from: global_model_full (1).h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_ROOT = \"/content/mia_results_fedprox\"\n",
        "ZIP_PATH = os.path.join(OUT_ROOT, \"mia_results_clients.zip\")"
      ],
      "metadata": {
        "id": "L0Ouu5A1ymKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_client_privacy(model, X_train, X_test, y_train, y_test,\n",
        "                           client_name=\"client\",\n",
        "                           clip_value=0.95, noise_std=0.0, top_k=None, round_ndigits=None,\n",
        "                           rng_seed=None, out_root=OUT_ROOT):\n",
        "\n",
        "    outdir = os.path.join(\"/content/mia_results_fedprox\", f\"mia_results_{client_name}\")\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    probs_train = privacy_predict_probs(model, X_train,\n",
        "                                        clip_value=clip_value,\n",
        "                                        noise_std=noise_std,\n",
        "                                        top_k=top_k,\n",
        "                                        round_ndigits=round_ndigits,\n",
        "                                        rng_seed=rng_seed)\n",
        "    probs_test  = privacy_predict_probs(model, X_test,\n",
        "                                        clip_value=clip_value,\n",
        "                                        noise_std=noise_std,\n",
        "                                        top_k=top_k,\n",
        "                                        round_ndigits=round_ndigits,\n",
        "                                        rng_seed=rng_seed+1 if rng_seed is not None else None)\n",
        "\n",
        "    conf_train = np.max(probs_train, axis=1)\n",
        "    conf_test  = np.max(probs_test, axis=1)\n",
        "\n",
        "    y_member_train = np.ones(len(conf_train), dtype=int)\n",
        "    y_member_test  = np.zeros(len(conf_test), dtype=int)\n",
        "\n",
        "    conf_all = np.concatenate([conf_train, conf_test])\n",
        "    y_member_all = np.concatenate([y_member_train, y_member_test])\n",
        "\n",
        "    # ROC and threshold\n",
        "    fpr, tpr, thresholds = roc_curve(y_member_all, conf_all)\n",
        "    youden = tpr - fpr\n",
        "    best_idx = np.argmax(youden)\n",
        "    best_thresh = thresholds[best_idx]\n",
        "\n",
        "    attack_preds = (conf_all >= best_thresh).astype(int)\n",
        "    ASR = accuracy_score(y_member_all, attack_preds)\n",
        "    AUC = roc_auc_score(y_member_all, conf_all)\n",
        "    cm = confusion_matrix(y_member_all, attack_preds, labels=[0,1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    privacy_score = 1.0 - ASR\n",
        "\n",
        "    # Save classification report\n",
        "    clr_text = classification_report(y_member_all, attack_preds, zero_division=0)\n",
        "    clr = classification_report(y_member_all, attack_preds, output_dict=True, zero_division=0)\n",
        "    with open(os.path.join(outdir, \"classification_report.txt\"), \"w\") as f:\n",
        "        f.write(clr_text)\n",
        "    pd.DataFrame(clr).transpose().to_csv(os.path.join(outdir, \"classification_report.csv\"))\n",
        "\n",
        "    # Save summary\n",
        "    summary = {\n",
        "        \"client\": client_name,\n",
        "        \"n_members_train\": int(len(conf_train)),\n",
        "        \"n_nonmembers_test\": int(len(conf_test)),\n",
        "        \"best_threshold\": float(best_thresh),\n",
        "        \"AUC\": float(AUC),\n",
        "        \"ASR\": float(ASR),\n",
        "        \"privacy_score\": float(privacy_score),\n",
        "        \"clip_value\": clip_value,\n",
        "        \"noise_std\": noise_std,\n",
        "        \"top_k\": top_k,\n",
        "        \"round_ndigits\": round_ndigits,\n",
        "        \"TP\": int(tp), \"FP\": int(fp), \"FN\": int(fn), \"TN\": int(tn)\n",
        "    }\n",
        "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    # ROC plot\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC (AUC={AUC:.4f}) - {client_name}\")\n",
        "    plt.savefig(os.path.join(outdir, \"roc_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Privacy score curve across thresholds\n",
        "    thr_grid = np.linspace(np.min(conf_all)-1e-6, np.max(conf_all)+1e-6, 200)\n",
        "    asr_list = [accuracy_score(y_member_all, (conf_all >= t).astype(int)) for t in thr_grid]\n",
        "    privacy_curve = 1.0 - np.array(asr_list)\n",
        "    pd.DataFrame({\"threshold\": thr_grid, \"ASR\": asr_list, \"privacy_score\": privacy_curve}).to_csv(os.path.join(outdir, \"privacy_curve_values.csv\"), index=False)\n",
        "    plt.figure()\n",
        "    plt.plot(thr_grid, privacy_curve)\n",
        "    plt.xlabel(\"Confidence threshold\")\n",
        "    plt.ylabel(\"Privacy score (1 - ASR)\")\n",
        "    plt.title(f\"Privacy curve - {client_name}\")\n",
        "    plt.savefig(os.path.join(outdir, \"privacy_score_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Confidence histograms\n",
        "    plt.figure()\n",
        "    plt.hist(conf_train, bins=50)\n",
        "    plt.title(f\"Confidence hist - members (train) - {client_name}\")\n",
        "    plt.savefig(os.path.join(outdir, \"conf_hist_train.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(conf_test, bins=50)\n",
        "    plt.title(f\"Confidence hist - non-members (test) - {client_name}\")\n",
        "    plt.savefig(os.path.join(outdir, \"conf_hist_test.png\"))\n",
        "    plt.close()\n",
        "    print(summary)\n",
        "\n",
        "    print(f\"Saved privacy-aware MIA results for {client_name} -> {outdir}\")\n",
        "    return outdir, summary"
      ],
      "metadata": {
        "id": "RLBg4Tuk1inx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRIVACY_PARAMS = {\n",
        "    \"clip_value\": 0.90,\n",
        "    \"noise_std\": 0.005,\n",
        "    \"top_k\": 3,\n",
        "    \"round_ndigits\": 3,\n",
        "    \"rng_seed\": 234\n",
        "}\n",
        "\n",
        "clients_dirs = []\n",
        "out1, sum1 = analyze_client_privacy(model, X1_train, X1_test, y1_train, y1_test,\n",
        "                                    client_name=\"client1\",\n",
        "                                    **PRIVACY_PARAMS)\n",
        "clients_dirs.append(out1)\n",
        "\n",
        "out2, sum2 = analyze_client_privacy(model, X2_train, X2_test, y2_train, y2_test,\n",
        "                                    client_name=\"client2\",\n",
        "                                    **PRIVACY_PARAMS)\n",
        "clients_dirs.append(out2)\n",
        "import zipfile, os\n",
        "# Zip results\n",
        "zip_path = \"/content/mia_results_fedprox/mia_results_clients.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for d in clients_dirs:\n",
        "        for root, _, files in os.walk(d):\n",
        "            for fn in files:\n",
        "                full = os.path.join(root, fn)\n",
        "                arc = os.path.relpath(full, OUT_ROOT)\n",
        "                zf.write(full, arc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvtaaA1-13v1",
        "outputId": "70040b63-0f25-4194-ec87-17520baa1b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'client': 'client1', 'n_members_train': 140272, 'n_nonmembers_test': 35069, 'best_threshold': 0.5830784913353722, 'AUC': 0.5024186755935535, 'ASR': 0.5971221790682156, 'privacy_score': 0.40287782093178437, 'clip_value': 0.9, 'noise_std': 0.005, 'top_k': 3, 'round_ndigits': 3, 'TP': 92574, 'FP': 22943, 'FN': 47698, 'TN': 12126}\n",
            "Saved privacy-aware MIA results for client1 -> /content/mia_results_fedprox/mia_results_client1\n",
            "{'client': 'client2', 'n_members_train': 140270, 'n_nonmembers_test': 35068, 'best_threshold': 0.9867986798679867, 'AUC': 0.5009744612406443, 'ASR': 0.43900922789127284, 'privacy_score': 0.5609907721087272, 'clip_value': 0.9, 'noise_std': 0.005, 'top_k': 3, 'round_ndigits': 3, 'TP': 55670, 'FP': 13763, 'FN': 84600, 'TN': 21305}\n",
            "Saved privacy-aware MIA results for client2 -> /content/mia_results_fedprox/mia_results_client2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/mia_results_fedprox/mia_results_clients.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gF0GFHpjy68i",
        "outputId": "7722146d-c66d-4aeb-df12-b381ebb2c747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f2ee94b8-a094-4586-82d0-3f8d0019748a\", \"mia_results_clients.zip\", 163740)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}